{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "train_num=int(len(train_images)*0.8)\n",
    "train_x=train_images[:train_num]\n",
    "train_y=train_labels[:train_num]\n",
    "valid_x=train_images[train_num:]\n",
    "valid_y=train_labels[train_num:]\n",
    "test_x=test_images\n",
    "test_y=test_labels\n",
    "\n",
    "train_x=train_x.reshape(-1,784)\n",
    "train_y=tf.one_hot(train_y,depth=10)\n",
    "valid_x=valid_x.reshape(-1,784)\n",
    "valid_y=tf.one_hot(valid_y,depth=10)\n",
    "test_x=test_x.reshape(-1,784)\n",
    "test_y=tf.one_hot(test_y,depth=10)\n",
    "\n",
    "train_x=tf.cast(train_x/255.0,tf.float32)\n",
    "valid_x=tf.cast(valid_x/255.0,tf.float32)\n",
    "test_x=tf.cast(test_x/255.0,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=tf.Variable(tf.random.normal([784,64],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b1=tf.Variable(tf.zeros([64]),dtype=tf.float32)\n",
    "w2=tf.Variable(tf.random.normal([64,32],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b2=tf.Variable(tf.zeros([32]),dtype=tf.float32)\n",
    "w3=tf.Variable(tf.random.normal([32,10],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b3=tf.Variable(tf.zeros([10]),dtype=tf.float32)\n",
    "w=[w1,w2,w3]\n",
    "b=[b1,b2,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,w,b):\n",
    "    x=tf.matmul(x,w[0])+b[0]\n",
    "    x=tf.nn.relu(x)\n",
    "    x=tf.matmul(x,w[1])+b[1]\n",
    "    x=tf.nn.relu(x)\n",
    "    x=tf.matmul(x,w[2])+b[2]\n",
    "    pred=tf.nn.softmax(x)\n",
    "    return pred\n",
    "def loss(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    loss_=tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_=loss(x,y,w,b)\n",
    "    return tape.gradient(loss_,w+b)\n",
    "def accuracy(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss_list_train=[]\n",
    "loss_list_valid=[]\n",
    "acc_list_train=[]\n",
    "acc_list_valid=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1, train loss=7.6598, train accuracy=0.5125, value loss=7.4909, value accuracy=:0.5235\n",
      "epoch= 2, train loss=4.5918, train accuracy=0.7057, value loss=4.5323, value accuracy=:0.7113\n",
      "epoch= 3, train loss=3.9995, train accuracy=0.7450, value loss=4.0040, value accuracy=:0.7442\n",
      "epoch= 4, train loss=3.5897, train accuracy=0.7714, value loss=3.6166, value accuracy=:0.7702\n",
      "epoch= 5, train loss=3.3548, train accuracy=0.7871, value loss=3.4307, value accuracy=:0.7814\n"
     ]
    }
   ],
   "source": [
    "train_epochs=5\n",
    "batch_size=50\n",
    "steps=int(train_num/batch_size)\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(steps):\n",
    "        xs=train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys=train_y[step*batch_size:(step+1)*batch_size]\n",
    "        grads=grad(xs,ys,w,b)\n",
    "        optimizer.apply_gradients(zip(grads,w+b))\n",
    "\n",
    "    loss_list_train.append(loss(train_x,train_y,w,b).numpy())\n",
    "    loss_list_valid.append(loss(valid_x,valid_y,w,b).numpy())\n",
    "    acc_list_train.append(accuracy(train_x,train_y,w,b).numpy())\n",
    "    acc_list_valid.append(accuracy(valid_x,valid_y,w,b).numpy())\n",
    "    print('epoch={:2d}, train loss={:.4f}, train accuracy={:.4f}, value loss={:.4f}, value accuracy=:{:.4f}'\n",
    "    .format(epoch+1,loss_list_train[-1],acc_list_train[-1],loss_list_valid[-1],acc_list_valid[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('TensorFlow_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eba1f01361cbcfebf806f3b68f7028338144b71e3783d6acf4b17241665e30f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
