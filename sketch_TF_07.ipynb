{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 01:03:08.006509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "train_num=int(len(train_images)*0.8)\n",
    "train_x=train_images[:train_num]\n",
    "train_y=train_labels[:train_num]\n",
    "valid_x=train_images[train_num:]\n",
    "valid_y=train_labels[train_num:]\n",
    "test_x=test_images\n",
    "test_y=test_labels\n",
    "\n",
    "train_x=train_x.reshape(-1,784)\n",
    "train_y=tf.one_hot(train_y,depth=10)\n",
    "valid_x=valid_x.reshape(-1,784)\n",
    "valid_y=tf.one_hot(valid_y,depth=10)\n",
    "test_x=test_x.reshape(-1,784)\n",
    "test_y=tf.one_hot(test_y,depth=10)\n",
    "\n",
    "train_x=tf.cast(train_x/255.0,tf.float32)\n",
    "valid_x=tf.cast(valid_x/255.0,tf.float32)\n",
    "test_x=tf.cast(test_x/255.0,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=tf.Variable(tf.random.normal([784,64],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b1=tf.Variable(tf.zeros([64]),dtype=tf.float32)\n",
    "w2=tf.Variable(tf.random.normal([64,32],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b2=tf.Variable(tf.zeros([32]),dtype=tf.float32)\n",
    "w3=tf.Variable(tf.random.normal([32,10],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b3=tf.Variable(tf.zeros([10]),dtype=tf.float32)\n",
    "w=[w1,w2,w3]\n",
    "b=[b1,b2,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_plot(image):\n",
    "    plt.imshow(image.reshape(28,28),cmap='binary')\n",
    "    plt.show()\n",
    "def model(x,w,b):\n",
    "    x=tf.nn.relu(tf.matmul(x,w[0])+b[0])\n",
    "    x=tf.nn.relu(tf.matmul(x,w[1])+b[1])\n",
    "    pred=tf.nn.softmax(tf.matmul(x,w[2])+b[2])\n",
    "    return pred\n",
    "def loss_function(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    loss_=tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        return tape.gradient(loss_function(x,y,w,b),w+b)\n",
    "def accuracy(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss_list_train=[]\n",
    "loss_list_valid=[]\n",
    "acc_list_train=[]\n",
    "acc_list_valid=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1, train loss=6.9348, train accuracy=0.5559, value loss=6.8983, value accuracy=:0.5573\n",
      "epoch= 2, train loss=3.9643, train accuracy=0.7413, value loss=3.9019, value accuracy=:0.7452\n",
      "epoch= 3, train loss=3.1103, train accuracy=0.7960, value loss=2.9847, value accuracy=:0.8045\n",
      "epoch= 4, train loss=2.5030, train accuracy=0.8347, value loss=2.3385, value accuracy=:0.8461\n",
      "epoch= 5, train loss=1.9964, train accuracy=0.8684, value loss=1.9212, value accuracy=:0.8728\n"
     ]
    }
   ],
   "source": [
    "train_epochs=5\n",
    "batch_size=50\n",
    "total_step=int(train_num/batch_size)\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs=train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys=train_y[step*batch_size:(step+1)*batch_size]\n",
    "        grads=grad(xs,ys,w,b)\n",
    "        optimizer.apply_gradients(zip(grads,w+b))\n",
    "\n",
    "    loss_list_train.append(loss_function(train_x,train_y,w,b).numpy())\n",
    "    loss_list_valid.append(loss_function(valid_x,valid_y,w,b).numpy())\n",
    "    acc_list_train.append(accuracy(train_x,train_y,w,b).numpy())\n",
    "    acc_list_valid.append(accuracy(valid_x,valid_y,w,b).numpy())\n",
    "    print('epoch={:2d}, train loss={:.4f}, train accuracy={:.4f}, value loss={:.4f}, value accuracy=:{:.4f}'\n",
    "    .format(epoch+1,loss_list_train[-1],acc_list_train[-1],loss_list_valid[-1],acc_list_valid[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('TensorFlow_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eba1f01361cbcfebf806f3b68f7028338144b71e3783d6acf4b17241665e30f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
