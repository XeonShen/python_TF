{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "train_num=int(len(train_images)*0.8)\n",
    "train_x=train_images[:train_num]\n",
    "train_y=train_labels[:train_num]\n",
    "valid_x=train_images[train_num:]\n",
    "valid_y=train_labels[train_num:]\n",
    "test_x=test_images\n",
    "test_y=test_labels\n",
    "\n",
    "train_x=train_x.reshape(-1,784)\n",
    "train_y=tf.one_hot(train_y,depth=10)\n",
    "valid_x=valid_x.reshape(-1,784)\n",
    "valid_y=tf.one_hot(valid_y,depth=10)\n",
    "test_x=test_x.reshape(-1,784)\n",
    "test_y=tf.one_hot(test_y,depth=10)\n",
    "\n",
    "train_x=tf.cast(train_x/255.0,tf.float32)\n",
    "valid_x=tf.cast(valid_x/255.0,tf.float32)\n",
    "test_x=tf.cast(test_x/255.0,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=tf.Variable(tf.random.normal([784,64],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b1=tf.Variable(tf.zeros([64]),dtype=tf.float32)\n",
    "w2=tf.Variable(tf.random.normal([64,32],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b2=tf.Variable(tf.zeros([32]),dtype=tf.float32)\n",
    "w3=tf.Variable(tf.random.normal([32,10],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b3=tf.Variable(tf.zeros([10]),dtype=tf.float32)\n",
    "w=[w1,w2,w3]\n",
    "b=[b1,b2,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,w,b):\n",
    "    x=tf.matmul(x,w[0])+b[0]\n",
    "    x=tf.nn.relu(x)\n",
    "    x=tf.matmul(x,w[1])+b[1]\n",
    "    x=tf.nn.relu(x)\n",
    "    x=tf.matmul(x,w[2])+b[2]\n",
    "    pred=tf.nn.softmax(x)\n",
    "    return pred\n",
    "def loss(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    loss_=tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_=loss(x,y,w,b)\n",
    "    return tape.gradient(loss_,[w,b])\n",
    "def accuracy(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.05\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss_list_train=[]\n",
    "loss_list_valid=[]\n",
    "acc_list_train=[]\n",
    "acc_list_valid=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [784,64] != values[1].shape = [64,32] [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     ys\u001b[39m=\u001b[39mtrain_y[step\u001b[39m*\u001b[39mbatch_size:(step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[1;32m      8\u001b[0m     grads\u001b[39m=\u001b[39mgrad(xs,ys,w,b)\n\u001b[0;32m----> 9\u001b[0m     optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads,w\u001b[39m+\u001b[39;49mb))\n\u001b[1;32m     11\u001b[0m loss_list_train\u001b[39m.\u001b[39mappend(loss(train_x,train_y,w,b)\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     12\u001b[0m loss_list_valid\u001b[39m.\u001b[39mappend(loss(valid_x,valid_y,w,b)\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:678\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    675\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    676\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[1;32m    679\u001b[0m     functools\u001b[39m.\u001b[39;49mpartial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply, apply_state\u001b[39m=\u001b[39;49mapply_state),\n\u001b[1;32m    680\u001b[0m     strategy,\n\u001b[1;32m    681\u001b[0m     grads_and_vars,\n\u001b[1;32m    682\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:723\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mwith\u001b[39;00m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    720\u001b[0m   \u001b[39mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    721\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m eagerly_outside_functions \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    722\u001b[0m       var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname):\n\u001b[0;32m--> 723\u001b[0m     update_op \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m    724\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    725\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    726\u001b[0m       \u001b[39m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[1;32m    727\u001b[0m       \u001b[39m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[1;32m    728\u001b[0m       update_ops\u001b[39m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2630\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2627\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2628\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2629\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2632\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2633\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3703\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3701\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3702\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3703\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3709\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3705\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3706\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3707\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3708\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3709\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3710\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   3711\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:706\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_apply_args:\n\u001b[1;32m    705\u001b[0m   apply_kwargs[\u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m apply_state\n\u001b[0;32m--> 706\u001b[0m update_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resource_apply_dense(grad, var, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mapply_kwargs)\n\u001b[1;32m    707\u001b[0m \u001b[39mif\u001b[39;00m var\u001b[39m.\u001b[39mconstraint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:170\u001b[0m, in \u001b[0;36mAdam._resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    167\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m'\u001b[39m\u001b[39mv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsgrad:\n\u001b[0;32m--> 170\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mraw_ops\u001b[39m.\u001b[39;49mResourceApplyAdam(\n\u001b[1;32m    171\u001b[0m       var\u001b[39m=\u001b[39;49mvar\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    172\u001b[0m       m\u001b[39m=\u001b[39;49mm\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    173\u001b[0m       v\u001b[39m=\u001b[39;49mv\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    174\u001b[0m       beta1_power\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_1_power\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m       beta2_power\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_2_power\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m       lr\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mlr_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m       beta1\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_1_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m       beta2\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_2_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m       epsilon\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mepsilon\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m       grad\u001b[39m=\u001b[39;49mgrad,\n\u001b[1;32m    181\u001b[0m       use_locking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_locking)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m   vhat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m'\u001b[39m\u001b[39mvhat\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/util/tf_export.py:400\u001b[0m, in \u001b[0;36mkwarg_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m args:\n\u001b[1;32m    396\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m{f}\u001b[39;00m\u001b[39m only takes keyword args (possible keys: \u001b[39m\u001b[39m{kwargs}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    398\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mPlease pass these args as kwargs instead.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    399\u001b[0m       \u001b[39m.\u001b[39mformat(f\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, kwargs\u001b[39m=\u001b[39mf_argspec\u001b[39m.\u001b[39margs))\n\u001b[0;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_training_ops.py:1431\u001b[0m, in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_apply_adam_eager_fallback(\n\u001b[1;32m   1432\u001b[0m       var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon,\n\u001b[1;32m   1433\u001b[0m       grad, use_locking\u001b[39m=\u001b[39;49muse_locking, use_nesterov\u001b[39m=\u001b[39;49muse_nesterov, name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1434\u001b[0m       ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m   1435\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m   1436\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_training_ops.py:1461\u001b[0m, in \u001b[0;36mresource_apply_adam_eager_fallback\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name, ctx)\u001b[0m\n\u001b[1;32m   1459\u001b[0m   use_nesterov \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m use_nesterov \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(use_nesterov, \u001b[39m\"\u001b[39m\u001b[39muse_nesterov\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1461\u001b[0m _attr_T, _inputs_T \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], ctx, [_dtypes\u001b[39m.\u001b[39;49mfloat32, _dtypes\u001b[39m.\u001b[39;49mfloat64, _dtypes\u001b[39m.\u001b[39;49mint32, _dtypes\u001b[39m.\u001b[39;49muint8, _dtypes\u001b[39m.\u001b[39;49mint16, _dtypes\u001b[39m.\u001b[39;49mint8, _dtypes\u001b[39m.\u001b[39;49mcomplex64, _dtypes\u001b[39m.\u001b[39;49mint64, _dtypes\u001b[39m.\u001b[39;49mqint8, _dtypes\u001b[39m.\u001b[39;49mquint8, _dtypes\u001b[39m.\u001b[39;49mqint32, _dtypes\u001b[39m.\u001b[39;49mbfloat16, _dtypes\u001b[39m.\u001b[39;49muint16, _dtypes\u001b[39m.\u001b[39;49mcomplex128, _dtypes\u001b[39m.\u001b[39;49mhalf, _dtypes\u001b[39m.\u001b[39;49muint32, _dtypes\u001b[39m.\u001b[39;49muint64, ])\n\u001b[1;32m   1462\u001b[0m (beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad) \u001b[39m=\u001b[39m _inputs_T\n\u001b[1;32m   1463\u001b[0m var \u001b[39m=\u001b[39m _ops\u001b[39m.\u001b[39mconvert_to_tensor(var, _dtypes\u001b[39m.\u001b[39mresource)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:271\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    269\u001b[0m       dtype \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m   ret \u001b[39m=\u001b[39m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t, dtype, ctx\u001b[39m=\u001b[39mctx) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m l]\n\u001b[1;32m    273\u001b[0m \u001b[39m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    275\u001b[0m keras_symbolic_tensors \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m ret \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39m_is_keras_symbolic_tensor(x)]\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:271\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m       dtype \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m   ret \u001b[39m=\u001b[39m [ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, dtype, ctx\u001b[39m=\u001b[39;49mctx) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m l]\n\u001b[1;32m    273\u001b[0m \u001b[39m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    275\u001b[0m keras_symbolic_tensors \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m ret \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39m_is_keras_symbolic_tensor(x)]\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1631\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1633\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1639\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1642\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1643\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1592\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m dtype \u001b[39m!=\u001b[39m inferred_dtype:\n\u001b[1;32m   1591\u001b[0m   v \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001b[0;32m-> 1592\u001b[0m \u001b[39mreturn\u001b[39;00m _autopacking_helper(v, dtype, name \u001b[39mor\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mpacked\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1499\u001b[0m, in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   1496\u001b[0m   \u001b[39m# NOTE: Fast path when all the items are tensors, this doesn't do any type\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m   \u001b[39m# checking.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(elem, core\u001b[39m.\u001b[39mTensor) \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m list_or_tuple):\n\u001b[0;32m-> 1499\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mpack(list_or_tuple, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1500\u001b[0m must_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m converted_elems \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:6548\u001b[0m, in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6546\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   6547\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 6548\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   6549\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   6550\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [784,64] != values[1].shape = [64,32] [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "train_epochs=5\n",
    "batch_size=50\n",
    "steps=int(train_num/batch_size)\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(steps):\n",
    "        xs=train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys=train_y[step*batch_size:(step+1)*batch_size]\n",
    "        grads=grad(xs,ys,w,b)\n",
    "        optimizer.apply_gradients(zip(grads,w+b))\n",
    "\n",
    "    loss_list_train.append(loss(train_x,train_y,w,b).numpy())\n",
    "    loss_list_valid.append(loss(valid_x,valid_y,w,b).numpy())\n",
    "    acc_list_train.append(accuracy(train_x,train_y,w,b).numpy())\n",
    "    acc_list_valid.append(accuracy(valid_x,valid_y,w,b).numpy())\n",
    "    print('epoch={:2d}, train loss={:.4f}, train accuracy={:.4f}, value loss={:.4f}, value accuracy=:{:.4f}'\n",
    "    .format(epoch+1,loss_list_train[-1],acc_list_train[-1],loss_list_valid[-1],acc_list_valid[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('TensorFlow_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eba1f01361cbcfebf806f3b68f7028338144b71e3783d6acf4b17241665e30f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
