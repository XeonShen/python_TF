{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:12:01.996010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "train_num=int(len(train_images)*0.8)\n",
    "train_x=train_images[:train_num]\n",
    "train_y=train_labels[:train_num]\n",
    "vaild_x=train_images[train_num:]\n",
    "vaild_y=train_labels[train_num:]\n",
    "test_x=test_images\n",
    "test_y=test_labels\n",
    "\n",
    "train_x=train_x.reshape(-1,784)\n",
    "train_y=tf.one_hot(train_y,depth=10)\n",
    "vaild_x=vaild_x.reshape(-1,784)\n",
    "vaild_y=tf.one_hot(vaild_y,depth=10)\n",
    "test_x=test_x.reshape(-1,784)\n",
    "test_y=tf.one_hot(test_y,depth=10)\n",
    "\n",
    "train_x=tf.cast(train_x/255.0,tf.float32)\n",
    "vaild_x=tf.cast(vaild_x/255.0,tf.float32)\n",
    "test_x=tf.cast(test_x/255.0,tf.float32)\n",
    "\n",
    "w=tf.Variable(tf.random.normal([784,10],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "b=tf.Variable(tf.zeros([10]),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_plot(image):\n",
    "    plt.imshow(image.reshape(28,28),cmap='binary')\n",
    "    plt.show()\n",
    "def model(x,w,b):\n",
    "    pred=tf.matmul(x,w)+b\n",
    "    return tf.nn.softmax(pred)\n",
    "def loss_function(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    loss_=tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        return tape.gradient(loss_function(x,y,w,b),[w,b])\n",
    "def accuracy(x,y,w,b):\n",
    "    pred=model(x,w,b)\n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss_list_train=[]\n",
    "loss_list_vaild=[]\n",
    "acc_list_train=[]\n",
    "acc_list_vaild=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1, train loss=1.8203, train accuracy=0.6781, value loss=1.6296, value accuracy=:0.7007\n",
      "epoch= 2, train loss=1.0656, train accuracy=0.7910, value loss=0.9390, value accuracy=:0.8106\n",
      "epoch= 3, train loss=0.8188, train accuracy=0.8323, value loss=0.7306, value accuracy=:0.8466\n",
      "epoch= 4, train loss=0.6912, train accuracy=0.8537, value loss=0.6272, value accuracy=:0.8628\n",
      "epoch= 5, train loss=0.6098, train accuracy=0.8675, value loss=0.5630, value accuracy=:0.8740\n"
     ]
    }
   ],
   "source": [
    "training_epochs=5\n",
    "batch_size=50\n",
    "total_step=int(train_num/batch_size)\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs=train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys=train_y[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        grads=grad(xs,ys,w,b)\n",
    "        optimizer.apply_gradients(zip(grads,[w,b]))\n",
    "    \n",
    "    loss_list_train.append(loss_function(train_x,train_y,w,b).numpy())\n",
    "    loss_list_vaild.append(loss_function(vaild_x,vaild_y,w,b).numpy())\n",
    "    acc_list_train.append(accuracy(train_x,train_y,w,b).numpy())\n",
    "    acc_list_vaild.append(accuracy(vaild_x,vaild_y,w,b).numpy())\n",
    "    print('epoch={:2d}, train loss={:.4f}, train accuracy={:.4f}, value loss={:.4f}, value accuracy=:{:.4f}'\n",
    "    .format(epoch+1,loss_list_train[-1],acc_list_train[-1],loss_list_vaild[-1],acc_list_vaild[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('TensorFlow_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eba1f01361cbcfebf806f3b68f7028338144b71e3783d6acf4b17241665e30f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
